{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAeEYTNbiGBfvB6BmS0Bpj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanlu29/juanlu29/blob/gp_aprendizaje/libreriaGP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juguGpOpG3HF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1cc40162-57de-4585-e5f1-7293a94b3d4d"
      },
      "source": [
        "# Modulos y constantes\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import scipy\n",
        "import scipy.linalg\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numba"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW6CbMb8KZmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pruebas con funciones anonimas en python\n",
        "\n",
        "class funcionesPrueba():\n",
        "  def __init__(self):\n",
        "    '''\n",
        "    Covarianza puede ser una cadena de texto o una funcion anónima como combinación de metodos de la clase\n",
        "    covarianza es un diccionario\n",
        "    '''\n",
        "    self.Kernels = self.kernels()\n",
        "\n",
        "  def calcCovM(self,x,y):\n",
        "    '''\n",
        "    Dados x e y como ndarrays, calcula la matriz de covarianzas cuyos elementos son evaluados de la forma\n",
        "    C(xi,yi) = (k(xi,yi)) con rango (nx x ny) donde nx y ny son la longitud de los vectores x  e y respectivamente.\n",
        "    hiper son los hiperparámetros usados en el modelo\n",
        "    '''\n",
        "    # Se crean matrices [[x],[x],...] (longitud de la concatenacion nx) y [[y],[y],...].T (longitud de la concatenacion ny)\n",
        "    xM = np.full((len(y),len(x)),x)\n",
        "    yM = (np.full((len(x),len(y)),y)).T\n",
        "    # Llamamos la funcion Ker que nos debe devolver como salida una matriz cuyos elementos calculados representan k(x,y)\n",
        "    return self.Ker(xM,yM,*self.Hiper)\n",
        "\n",
        "\n",
        "  def compCov(self,covarianza,*hiper):\n",
        "    '''\n",
        "    Permite definir el kernel a usar por el proceso gaussiano, tanto si es uno de los kernels definidos en la clase como si es una combinacion de los mismos\n",
        "    El argumento es una funcion anónima en caso de ser una composición, en caso contrario es suficiente con proporcionar el nombre del kernel definido\n",
        "    hiper son los hiperparámetros que precisan el kernel y vienen dado por un diccionario\n",
        "    '''\n",
        "    self.Hiper = hiper\n",
        "    self.Ker = lambda x_test, x_obs, *hiper: covarianza(x_test,x_obs,*self.Hiper) # Covarianza definida\n",
        "\n",
        "  class kernels():\n",
        "    '''\n",
        "    Se definen kernels de uso común junto a sus hiperparámetros\n",
        "    '''\n",
        "    def __init__(self):\n",
        "      return\n",
        "\n",
        "    def exponencialCuadrada(self,xb,xa,s,l):\n",
        "      '''\n",
        "      Correlacion estacionaria (depende solo de la distancia r = abs(xb-xa)) con decaimiento exponencial cuadratico\n",
        "      Hiperparámetros:\n",
        "      s : amplitud de la correlacion, esta relacionado con la amplitud de las trayectorias generadas por el GP\n",
        "      l : escala de longitud del GP. Esta relacionada con la distancia sobr la cual los procesos generados por el GP pueden presentar oscilaciones o variaciones\n",
        "      '''\n",
        "      return np.power(s,2)*np.exp(-np.power(xa-xb,2)/(2.*np.power(l,2)))\n",
        "\n",
        "    def ruidoBlanco(self,xb,xa,sigma):\n",
        "      '''\n",
        "      Correlaciones de ruido blanco o gaussiano puro, solo correlaciona los puntos consigo mismo. \n",
        "      Representa incertidumbres intrínsecas en las observaciones y asume una distribución a priori de esos errores gaussiano\n",
        "      Hiperparáámetros:\n",
        "      s : amplitud o incertidumbre del ruido generado\n",
        "      '''\n",
        "      return np.where(xb==xa, np.power(sigma,2),0.) # Se usa el metodo numpy.where porque las operaciones logicas sobre arrays son consideradas ambiguas en el intérprete de python\n",
        "                                                    # Esta manera es válidad para python para comprar elemento a elemento entre matrices."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN9rSp4AQ88-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "439e37a9-f355-4eb2-a86c-5347fc5a1563"
      },
      "source": [
        "x_test = np.linspace(1.,5.,4)\n",
        "x_obs = np.linspace(1.,5.,4)\n",
        "x_obs = x_obs.T\n",
        "print(x_test,x_obs)\n",
        "prueba = funcionesPrueba()\n",
        "s = 3.\n",
        "l = 4.\n",
        "sigma = 0.\n",
        "prueba.compCov(lambda x,y,s,l,sigma: prueba.Kernels.exponencialCuadrada(x,y,s,l)+prueba.Kernels.ruidoBlanco(x,y,sigma),s,l,sigma) # Aqui especificamos los hiperparametros\n",
        "print(prueba.calcCovM(x_test,x_obs,s,l,sigma))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.         2.33333333 3.66666667 5.        ] [1.         2.33333333 3.66666667 5.        ]\n",
            "[[9.         8.51363522 7.20663663 5.45877594]\n",
            " [8.51363522 9.         8.51363522 7.20663663]\n",
            " [7.20663663 8.51363522 9.         8.51363522]\n",
            " [5.45877594 7.20663663 8.51363522 9.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i290_E_ZUG9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2d38376c-2107-4ed5-eee6-ed2866184bc3"
      },
      "source": [
        "print(x_test,x_obs)\n",
        "x = 3.66666667\n",
        "y = 5.\n",
        "a = 3.*3.*np.exp(-np.power((x-y),2)/(2.*4.*4.))\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.         2.33333333 3.66666667 5.        ] [1.         2.33333333 3.66666667 5.        ]\n",
            "8.513635222525789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djR_jiyCGlbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class gaussProcess():\n",
        "  def __init__(self):\n",
        "    '''\n",
        "    Los objetos de esta clase modelan procesos gaussianos caracterizados por su promedio y covarianza\n",
        "    '''\n",
        "    #self.Derivadas = prior_Partial_Der\n",
        "    self.Kernels = self.kernels()\n",
        "\n",
        "  def calcCovM(self,x,y,*hiper):\n",
        "    '''\n",
        "    Dados x e y como ndarrays, calcula la matriz de covarianzas cuyos elementos son evaluados de la forma\n",
        "    C(xi,yi) = (k(xi,yi)) con rango (nx x ny) donde nx y ny son la longitud de los vectores x  e y respectivamente.\n",
        "    hiper son los hiperparámetros usados en el modelo\n",
        "    '''\n",
        "    # Se crean matrices [[x],[x],...] (longitud de la concatenacion nx) y [[y],[y],...].T (longitud de la concatenacion ny)\n",
        "    xM = np.full((len(y),len(x)),x)\n",
        "    yM = (np.full((len(x),len(y)),y)).T\n",
        "    # Llamamos la funcion Ker que nos debe devolver como salida una matriz cuyos elementos calculados representan k(x,y)\n",
        "    return self.Ker(xM,yM,*hiper)\n",
        "\n",
        "  def calcDerCovM(self,x,y):\n",
        "    '''\n",
        "    Dados x e y como ndarrays, calcula la matriz correspondiente a la derivada respecto los hiperparámetros de las covarianzas\n",
        "    cuyos elementos son evaluados de la forma C_j(xi,yi) = (dk(xi,yi)dh_j) con rango (nx x ny) donde nx y ny son la longitud de los \n",
        "    vectores x e y respectivamente. Hiper son los hiperparámetros usados en el modelo\n",
        "    '''\n",
        "    # Se crean matrices [[x],[x],...] (longitud de la concatenacion nx) y [[y],[y],...].T (longitud de la concatenacion ny)\n",
        "    xM = np.full((len(y),len(x)),x)\n",
        "    yM = (np.full((len(x),len(y)),y)).T\n",
        "    # Generamos el array de matrices llamando al zip de las funciones de derivadas y sus hiperparámetros para generarlas\n",
        "    return np.asarray([ self.DerKer[i](xM,yM,*self.Der_Hiper) for i in range(len(self.DerKer)) ] )\n",
        "\n",
        "  def compCov(self,covarianza,*hiper):\n",
        "    '''\n",
        "    Permite definir el kernel a usar por el proceso gaussiano, tanto si es uno de los kernels definidos en la clase como si es una combinacion de los mismos\n",
        "    El argumento es una funcion anónima en caso de ser una composición, en caso contrario es suficiente con proporcionar el nombre del kernel definido\n",
        "    hiper son los hiperparámetros que precisan el kernel y vienen dado por un diccionario\n",
        "    '''\n",
        "    self.Hiper = hiper\n",
        "    self.N_iter = len(hiper)\n",
        "    self.Ker = covarianza # Covarianza definida\n",
        "    self.Ker = np.vectorize(self.Ker)\n",
        "\n",
        "  def compDerCov(self,dominio,observacion,derCovarianza,*hiper):\n",
        "    '''\n",
        "    Permite definir la expresion para la derivada del kernel respecto los distintos hiperparametros como un iterable zip\n",
        "    de funciones anonimas juntos a sus hiperparámetros. \n",
        "    En este caso por propositos de optimizacion se espera que se evalue dinamicamente con distintos hiperparámetros.\n",
        "    Los datos contenidos en *hiper están encapsulados en una tupla a la que se debe acceder previamente\n",
        "    '''\n",
        "    self.Der_Hiper = hiper\n",
        "    self.Dominio = dominio\n",
        "    self.Observacion = observacion\n",
        "    try:\n",
        "      self.DerKer = derCovarianza\n",
        "    except:\n",
        "      raise NameError(\"No se ha definido kernel previamente\")\n",
        "\n",
        "\n",
        "  class kernels():\n",
        "    '''\n",
        "    Se definen kernels de uso común junto a sus hiperparámetros y derivadas asociadas\n",
        "    '''\n",
        "    def __init__(self):\n",
        "      return\n",
        "\n",
        "    def exponencialCuadrada(self,xb,xa,s,l):\n",
        "      '''\n",
        "      Correlacion estacionaria (depende solo de la distancia r = abs(xb-xa)) con decaimiento exponencial cuadratico\n",
        "\n",
        "      k(xb,xa) = s² exp( - (xb-xa)²/(2 l²) )\n",
        "\n",
        "      Hiperparámetros:\n",
        "      s : amplitud de la correlacion, esta relacionado con la amplitud de las trayectorias generadas por el GP\n",
        "      l : escala de longitud del GP. Esta relacionada con la distancia sobr la cual los procesos generados por el GP pueden presentar oscilaciones o variaciones\n",
        "      '''\n",
        "      return np.power(s,2)*np.exp(-np.power(xa-xb,2)/(2.*np.power(l,2)))\n",
        "\n",
        "    def expCua_der_s(self,xb,xa,s,l):\n",
        "      '''\n",
        "      Derivada respecto el hiperparámetro s de las correlaciones estacionarias con decaimiento exponenciales cuadráticas\n",
        "\n",
        "      k(xb,xa) = 2s exp( - (xb-xa)²/(2 l²) )\n",
        "\n",
        "      Hiperparámetros:\n",
        "      s : amplitud de la correlacion, esta relacionado con la amplitud de las trayectorias generadas por el GP\n",
        "      l : escala de longitud del GP. Esta relacionada con la distancia sobr la cual los procesos generados por el GP pueden presentar oscilaciones o variaciones\n",
        "      '''\n",
        "      return 2*s*np.exp(-np.power(xa-xb,2)/(2.*np.power(l,2)))\n",
        "\n",
        "    def expCua_der_l(self,xb,xa,s,l):\n",
        "      '''\n",
        "      Derivada respecto el hiperparámetro l de las correlaciones estacionarias con decaimiento exponenciales cuadráticas\n",
        "\n",
        "      k(xb,xa) = s²(xb-xa)² / l³ exp( - (xb-xa)²/(2 l²) )\n",
        "\n",
        "      Hiperparámetros:\n",
        "      s : amplitud de la correlacion, esta relacionado con la amplitud de las trayectorias generadas por el GP\n",
        "      l : escala de longitud del GP. Esta relacionada con la distancia sobr la cual los procesos generados por el GP pueden presentar oscilaciones o variaciones\n",
        "      '''\n",
        "      return (np.power(s*(xa-xb),2)/np.power(l,3))*np.exp(-np.power(xa-xb,2)/(2.*np.power(l,2)))\n",
        "\n",
        "    def ruidoBlanco(self,xb,xa,sigma):\n",
        "      '''\n",
        "      Correlaciones de ruido blanco o gaussiano puro, solo correlaciona los puntos consigo mismo. \n",
        "\n",
        "      k(xb,xa) = sigma² delta(xb,xa)\n",
        "\n",
        "      Representa incertidumbres intrínsecas en las observaciones y asume una distribución a priori de esos errores gaussiano\n",
        "      Hiperparáámetros:\n",
        "      s : amplitud o incertidumbre del ruido generado\n",
        "      '''\n",
        "      return np.where(xb==xa, np.power(sigma,2),0.) # Se usa el metodo numpy.where porque las operaciones logicas sobre arrays son consideradas ambiguas en el intérprete de python\n",
        "                                                    # Esta manera es válidad para python para comprar elemento a elemento entre matrices.\n",
        "\n",
        "    def rB_der_sigma(self,xb,xa,sigma):\n",
        "      '''\n",
        "      Derivada respecto el hiperparámetro sigma del ruido no correlacionado\n",
        "\n",
        "      k(xb,xa) = sigma² delta(xb,xa)\n",
        "\n",
        "      Representa incertidumbres intrínsecas en las observaciones y asume una distribución a priori de esos errores gaussiano\n",
        "      Hiperparáámetros:\n",
        "      s : amplitud o incertidumbre del ruido generado\n",
        "      '''\n",
        "      return np.where(xb==xa, 2*sigma,0.) # Se usa el metodo numpy.where porque las operaciones logicas sobre arrays son consideradas ambiguas en el intérprete de python\n",
        "                                          # Esta manera es válidad para python para comprar elemento a elemento entre matrices.\n",
        "\n",
        " \n",
        "  def cholDescomp(self,K):\n",
        "    '''\n",
        "    Descomposicion cholesky de una matriz dada\n",
        "    '''\n",
        "    try:\n",
        "      L = scipy.linalg.cholesky(K, lower=True)\n",
        "    except:\n",
        "     # L = scipy.linalg.cholesky(K + np.diag(0.000001*np.ones(int(np.sqrt(K.size)))), lower=True)\n",
        "      raise NameError(\"No es posible efectuar descomposicion cholesky\")\n",
        "\n",
        "    return L\n",
        "\n",
        "  def calcInvK(self,matriz):\n",
        "    '''\n",
        "    Calculo de la inversa de matriz. \n",
        "    '''\n",
        "    # Calculo de matriz inversa de la covarianza. \n",
        "    try:\n",
        "      invK = np.linalg.inv(matriz)\n",
        "    except:\n",
        "      raise NameError(\"No es posible calcular matriz inversa\")\n",
        "\n",
        "    return invK\n",
        "\n",
        "  def condicionarGP(self,dominio,observaciones,*dominio_test):\n",
        "    '''\n",
        "    Dadas unas observaciones junto a sus valores de dominio (uni-dimensionales) en el rango sobre el que se modela el GP, \n",
        "    obtiene la covarianza asociada a la distribución de trayectorias condicionadas al conjunto de partida dado un dominio \n",
        "    de test en el que queremos comprobar la predicción. Por tanto permite generar las trayectorias compatibles con los datos\n",
        "\n",
        "    También calcula el logaritmo de la probabilidad de verosimilitud marginal (marginal likelihood) de las observaciones dados los inputs \n",
        "    y parámetros del modelo usado.\n",
        "\n",
        "    Este algoritmo esta especificado en el libro \"Gaussian Processes for Machine Learning\", como algoritmo 2.1\n",
        "    '''\n",
        "    self.xtrain = dominio\n",
        "    self.ytrain = observaciones\n",
        "    self.xtest = dominio_test\n",
        "\n",
        "    # Definimos nueva covarianza\n",
        "    # Primero se realiza la descomposición cholesky de la adición de la covarianza de la distribución a priori,\n",
        "    # para lo cual calculamos la matriz de covarianza asociada al dominio de las observaciones sobre si mismo\n",
        "    # y al cruce del dominio de las observaciones y del test de prediccion.\n",
        "    try:\n",
        "      self.Cov_obs_obs = self.calcCovM(self.xtrain,self.xtrain,*self.Hiper)\n",
        "      self.Cov_obs_test = self.calcCovM(self.xtrain,self.xtest,*self.Hiper)\n",
        "    except:\n",
        "      raise NameError(\"Debes especificar primero el kernel que estas usando junto a sus hiperparametros con el metodo self.compCov\")\n",
        "\n",
        "    cholL = np.linalg.cholesky(self.Cov_obs_obs)\n",
        "\n",
        "    # Calculo del vector alfa como solucion del sistema K_obs_obs*alfa = y_entrenamiento usando la descomposición cholesky anterior\n",
        "    self.Alfa = scipy.linalg.cho_solve((cholL,True),self.ytrain)\n",
        "\n",
        "    # Vector v solución particular del sistema cholL*v = k_test para todos los datos del entrenamiento.\n",
        "    # Este sistema se resuelve introduciendo k_star no como matriz columna sino como la submatriz calculada como la evaluación de la covarianza a priori de los inputs de los valores a predecir y los inputs del entrenamiento\n",
        "    v = scipy.linalg.solve_triangular(cholL,self.cov_obs_test, lower=True)\n",
        "\n",
        "    # Se obtiene el valor promedio del proceso predictivo condicionado a las observaciones\n",
        "    self.Media_pred = np.matmul(self.Cov_obs_test.T,self.Alfa)\n",
        "\n",
        "    # Covarianza predictiva o condicionada. El proceso llevado a cabo ha sido obtener la distribución condicionada del GP a las observaciones\n",
        "    # Intenta calcular directamente la matriz, en caso contrario calcular la matriz de covarianza de la distribucion a priori dado el test\n",
        "    try:\n",
        "      self.Cov_pred = self.Cov_priori - np.matmul(v.T,v)\n",
        "    except:\n",
        "      # En caso que no esté definida o no coincida con la dimensionalidad del test, se recalcula la covarianza a priori\n",
        "      self.Cov_priori = self.calcCovM(self.xtest,self.xtest,*self.Hiper)\n",
        "      self.Cov_pred = self.Cov_priori - np.matmul(v.T,v)\n",
        "\n",
        "    # La siguiente matriz descompuesta es necesaria para generar procesos del GP.\n",
        "    self.L_pred = self.cholDescomp(self.Cov_pred)\n",
        "  \n",
        "\n",
        "  def log_prob_verosimilitud_datos(self,dominio,observaciones):\n",
        "    '''\n",
        "    Dadas unas observaciones, kernel e hiperparámetros dados, calcula el logaritmo de la probabilidad de verosimilitud de las observaciones al modelo y sus parámetros\n",
        "    '''\n",
        "\n",
        "    # Primero se realiza la descomposición cholesky de la adición de la covarianza de la distribución a priorir y el término de ruido.\n",
        "    #cholL = np.linalg.cholesky(self.calcCovM(dominio,dominio,*self.Hiper))\n",
        "    dominio = np.reshape(dominio,(len(dominio),1))\n",
        "    cholL = np.linalg.cholesky(self.Ker(dominio.T,dominio,*self.Hiper))\n",
        "\n",
        "    # Calculo del vector alfa como solucion del sistema K*alfa = y_entrenamiento usando la descomposición cholesky anterior\n",
        "    alfa = scipy.linalg.cho_solve((cholL,True),observaciones)\n",
        "\n",
        "    # Calculo de la probabilidad de verosimilitud marginal a este modelo y sus parámetros\n",
        "    self.log_marg_y = - 0.5*np.dot(alfa,observaciones) - np.sum(np.log(np.diag(cholL)),axis=0) - (float(len(dominio))/2.)*np.log(2*np.pi)\n",
        "    if (self.log_marg_y < -70.):\n",
        "      self.log_marg_y = 0.\n",
        "\n",
        "  def der_log_prob_ver_hiper(self,*hiper):\n",
        "    '''\n",
        "    Derivada del logaritmo de la probabilidad de verosimilitud respecto hiperapametros,\n",
        "    devuelve un ndarray con cada componenete correspondiendo a la matriz del modelo respecto\n",
        "    los distintos. La expresion es la siguiente\n",
        "\n",
        "    1/2 traza[  {alfa*alfa.T - K⁻¹} dK/dh] ; alfa = K⁻¹\\y\n",
        "\n",
        "    '''\n",
        "\n",
        "    # Definimos nueva covarianza\n",
        "    try:\n",
        "      covDom = self.calcCovM(self.Dominio,self.Dominio,*hiper)\n",
        "    except:\n",
        "      raise NameError(\"Debes especificar primero el kernel que estas usando junto a sus hiperparametros con el metodo self.compCov\")\n",
        "\n",
        "\n",
        "    invCovDom = self.calcInvK(covDom)\n",
        "\n",
        "    cholL = np.linalg.cholesky(covDom)\n",
        "\n",
        "    # Calculo del vector alfa como solucion del sistema K_obs_obs*alfa = y_entrenamiento usando la descomposición cholesky anterior\n",
        "    alfa = scipy.linalg.cho_solve((cholL,True),self.Observacion)\n",
        "\n",
        "    alfa = np.reshape(alfa,(len(alfa),1))\n",
        "\n",
        "    self.Der_Hiper = hiper\n",
        "    derCovHiper = self.calcDerCovM(self.Dominio,self.Dominio)\n",
        "    return 0.5*np.trace(np.matmul(np.matmul(alfa,alfa.T)-invCovDom,derCovHiper),axis1=1,axis2=2) # La suma de la traza en un array de mas de 2 dimensiones debe especificarse sobre sus indices. En este caso es dimensióón 3.\n",
        "    \n",
        "\n",
        "  def prioriGP(self,x_test):\n",
        "    '''\n",
        "    Computa los términos necesarios para extraer realizaciones del GP siguiendo la distribución a priori\n",
        "    '''\n",
        "    try:\n",
        "      self.Cov_priori = self.calcCovM(self.xtest,self.xtest,*self.Hiper)\n",
        "    except:\n",
        "      raise NameError(\"Debes especificar primero el kernel que estas usando junto a sus hiperparametros con el metodo self.compCov\")\n",
        "\n",
        "    self.xtest = x_test\n",
        "\n",
        "    # La siguiente matriz descompuesta es necesaria para generar procesos del GP.\n",
        "    self.L_priori = self.cholDescomp(self.Cov_pred)\n",
        "\n",
        "\n",
        "  def procesosPrioriGP(self):\n",
        "    '''\n",
        "    Genera realizaciones del proceso gaussiano dada la descomposicion cholesky de la matriz de covarianzas y la media correspondiente\n",
        "    '''\n",
        "    # Si no se ha calculado la descomposicióón de la covarianza se llama al método aqui\n",
        "    try:\n",
        "      return self.Mean_priori +  np.matmul(self.L_priori,(np.randn(len(self.xtest))).T)\n",
        "    except:\n",
        "      raise NameError(\"No se ha incluido los valores del dominio sobre los que muestrear el proceso o no se ha calculado la descomposición de la covarianza\")\n",
        "\n",
        "  def procesosCondicionadosGP(self):\n",
        "    '''\n",
        "    Genera realizaciones del proceso gaussiano dada la descomposicion cholesky de la matriz de covarianzas y la media correspondiente\n",
        "    '''\n",
        "    try:\n",
        "      return self.Media_pred + np.matmul(self.L_pred,(np.randn(len(self.xtest))).T)\n",
        "    except:\n",
        "      raise NameError(\"El GP no ha sido condicionado a las observaciones\")\n",
        "\n",
        "  def sigmaCalc(self,cov):\n",
        "    '''\n",
        "    Desviacion estándar punto a punto del proceso gausiano dado por la matriz de covarianza \n",
        "    Es la raiz cuadrado de los elementos de la diagonal de la matriz de covarianzas del proceso generado\n",
        "    '''\n",
        "    return np.sqrt(np.diag(cov))\n",
        "\n",
        "\n",
        "  def correlacionPuntoPunto(self):\n",
        "    '''\n",
        "    Obtiene la correlacion punto a punto dado un inputo concreto por el indice i_x\n",
        "    '''\n",
        "    try:\n",
        "      self.corrPP_pred = np.array([ self.K_pred[i,:] for i in range(len(self.K_pred)) ])\n",
        "    except:\n",
        "      print(\" Proceso gaussiano no entrenado aún, no existe K_pred \")\n",
        "    self.corrPP_prior = np.array([ self.K_prior[i,:] for i in range(len(self.K_prior)) ])\n",
        "\n",
        "  \n",
        "  def derivada_LO_CV(self,*args):\n",
        "    '''\n",
        "    Dadas unas observaciones particulares estima la derivada de la suma de los logaritmos de la evaluación de la distribución de probabilidad marginal de verosimilitud a que subconjuntos\n",
        "    de las observaciones están condicionadas al resto, respecto a los hiperparámetros del modelo. Si se encuentra el máximo de este valor, estamos asegurándonos de que con los hiperparámetros ajustados\n",
        "    las \"predicciones\" tras generar trayectorias del proceso gausiano que corresponderían a los subconjuntos excluidos sucesivamente son las más probables que el modelo puede hacer. Al ser la suma, esta optimización \n",
        "    es global y abarca la aproximación de observacion/test de todos los subconjuntos.\n",
        "    '''\n",
        "\n",
        "    if not isinstance(args[0], np.ndarray):\n",
        "      raise NameError(\"Las observaciones dadas para calcular la derivada del logaritmo de la distribución marginal de verosimilitud no es un array con datos\")\n",
        "    else:\n",
        "      observaciones = args[0]\n",
        "\n",
        "    # Vector auxiliar alpha y matriz auxiliar Z y la diagonal de la inversa de la distribucion a priori\n",
        "    try:\n",
        "      alpha = np.matmul(self.invK,observaciones)\n",
        "      invK_diag = np.diag(self.invK)\n",
        "      zeta = [np.matmul(self.invK,self.Derivadas[i]) for i in range(len(self.Derivadas)) ] # Es una lista de matrices\n",
        "      zeta_K = [np.diag(np.matmul(zeta[i],self.invK)) for i in range(len(self.Derivadas)) ]\n",
        "      alpha_invK = np.multiply(alpha,1./invK_diag)\n",
        "    except:\n",
        "      raise NameError(\"Necesitas calcular la matriz inversa de covarianzas de la distribución a priori\")\n",
        "    \n",
        "    termino_1 = [np.matmul(np.matmul(alpha_invK,zeta[i]),alpha) for i in range(len(self.Derivadas)) ] # Debido a Z esto es una lista\n",
        "    termino_2 = [np.sum(np.multiply(np.multiply(0.5*(1. + np.multiply(np.power(alpha,2),1./invK_diag)),zeta_K[i]),1./invK_diag)) for i in range(len(self.Derivadas)) ] # Debido a zeta_K esto es una lista\n",
        "\n",
        "    # Calculo. Es el valor de la derivada del logaritmo\n",
        "    self.derVerLOO = np.asarray([ termino_1[i] + termino_2[i] for i in range(len(self.Derivadas))])\n",
        "    "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7Ogka96GyNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class datosVisualizacion():\n",
        "  '''\n",
        "  Esta clase contiene los datos de entrenamiento y realizaciones de los procesos gaussianos para la visualización de los mismos\n",
        "  '''\n",
        "  def __init__(self,Titulo):\n",
        "    self.x = []\n",
        "    self.y = []\n",
        "    self.sigma = []\n",
        "    self.realizacion_dict = {}\n",
        "    self.titulo = Titulo\n",
        "    self.inicializacionPlot()\n",
        "\n",
        "  def inicializacionPlot(self):\n",
        "    '''\n",
        "    Inicializa el objeto matplotlib\n",
        "    '''\n",
        "    self.fig,self.ax = plt.subplots(nrows=1,ncols=1,figsize=(10,10))\n",
        "    self.ax.set_title(self.titulo)\n",
        "    self.fig_hm, self.ax_hm = plt.subplots(nrows=1,ncols=1,figsize=(10,10))\n",
        "\n",
        "  def add_covariance(self, cov):\n",
        "    '''\n",
        "    Añada matriz de covarianza y alternativamente calcula la covarianza del proceso gaussiano sobre el dominio\n",
        "    '''\n",
        "\n",
        "    self.cov_GP = cov\n",
        "\n",
        "  def add_mean(self,X,Mean):\n",
        "    '''\n",
        "    Almacena la desviación estándar de un proceso gausiano dado\n",
        "    '''\n",
        "    self.x_mean = X\n",
        "    self.mean = Mean\n",
        "\n",
        "\n",
        "  def add_sigma(self,X,Sigma):\n",
        "    '''\n",
        "    Almacena la desviación estándar de un proceso gausiano dado\n",
        "    '''\n",
        "    self.x_sigma = X\n",
        "    self.sigma = Sigma\n",
        "    self.meanMarker = 'r-'\n",
        "\n",
        "  def add_train_data(self,X,Y):\n",
        "    self.xtrain = X\n",
        "    self.ytrain = Y\n",
        "    self.marker = 'b*'\n",
        "\n",
        "  def add_data(self,X,Y,label):\n",
        "    self.x.append(X)\n",
        "    self.y.append(Y)\n",
        "    self.realizacion_dict[label] = len(self.x)-1\n",
        "\n",
        "  def add_corrPuntoPunto(self,corrPP, corrInputs):\n",
        "    '''\n",
        "    Añade correlaciones punto a punto sobre un dominio dado por los valores corrInputs\n",
        "    '''\n",
        "    self.corrPP = corrPP\n",
        "    self.corr_in = corrInputs\n",
        "\n",
        "  def add_data_plot(self,label):\n",
        "    try:\n",
        "      self.ax.plot(self.x[self.realizacion_dict[label]],self.y[self.realizacion_dict[label]],'g--')\n",
        "    except:\n",
        "      print('No existe datos referentes a etiqueta :',label)\n",
        "\n",
        "  def add_train_data_plot(self):\n",
        "    try:\n",
        "      self.ax.plot(self.xtrain,self.ytrain,self.marker)\n",
        "    except:\n",
        "      print('No existen datos de entrenamiento')\n",
        "\n",
        "  def add_mean_plot(self):\n",
        "    try:\n",
        "      self.ax.plot(self.x_mean,self.mean,self.meanMarker)\n",
        "    except:\n",
        "      print('No existen datos de entrenamiento')\n",
        "\n",
        "\n",
        "\n",
        "  def contorno_sigma(self):\n",
        "    '''\n",
        "    Muestra en pantalla contorno de 1 y 2 veces los valores de sigma del proceso gausiano\n",
        "    '''\n",
        "    self.ax.fill(np.concatenate((self.x_sigma,self.x_sigma[::-1])),\n",
        "             np.concatenate((self.mean - 1.9600 * self.sigma,\n",
        "                             (self.mean + 1.9600 * self.sigma)[::-1])),\n",
        "             alpha=.45, fc='y', ec='None', label='95% confidence interval')\n",
        "    self.ax.fill(np.concatenate((self.x_sigma,self.x_sigma[::-1])),\n",
        "             np.concatenate((self.mean - 1.000 * self.sigma,\n",
        "                             (self.mean + 1.000 * self.sigma)[::-1])),\n",
        "             alpha=.35, fc='b', ec='None', label='68% confidence interval')\n",
        "    \n",
        "  def plotCorrPuntoPunto(self,indices):\n",
        "    '''\n",
        "    Visualiza correlaciones punto a punto para los inputs dados por sus indices en la lista indices como argumento del metodo\n",
        "    '''\n",
        "\n",
        "    ' Generamos y visualizamos las imagen directamente en este metodo'\n",
        "    self.fig_cpp, self.ax_cpp = plt.subplots(nrows=1,ncols=1,figsize=(10,10))\n",
        "    try:\n",
        "      [self.ax_cpp.plot(self.corr_in,self.corrPP[indice],'-') for indice in indices] \n",
        "    except:\n",
        "      print('No existe datos referentes referentes a correlaciones punto a punto')\n",
        "    self.ax_cpp.grid(True)\n",
        "    self.fig_cpp.show()\n",
        "\n",
        "\n",
        "\n",
        "  def mostrarPlot(self):\n",
        "    '''\n",
        "    Muestra plot\n",
        "    '''\n",
        "    self.add_mean_plot()\n",
        "    self.add_train_data_plot()\n",
        "    self.contorno_sigma()\n",
        "    self.ax.grid(True)\n",
        "    self.fig.show()\n",
        "\n",
        "  def hmapCov(self):\n",
        "    '''\n",
        "    Visualiza covarianza como campo bidimensional\n",
        "    '''\n",
        "    plotRange = np.arange(len(self.cov_GP))\n",
        "    heatmap = self.ax_hm.pcolormesh(self.cov_GP,cmap='RdBu_r')\n",
        "    self.ax_hm.axis([plotRange.min(), plotRange.max(), plotRange.max(), plotRange.min()])\n",
        "    self.fig_hm.colorbar(heatmap, ax=self.ax_hm)\n",
        "    self.fig_hm.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SciOihGB3HVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "outputId": "4d4a3874-cc20-48df-b3b6-d29bf88f30dd"
      },
      "source": [
        "import time\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "#x_train = np.linspace(0.1,9.7,5)\n",
        "#y_train = 1.1*np.sin(2.*x_train) + np.asarray([random.gauss(0.,1.) for i in range(len(x_train))])\n",
        "x_train = np.array([-7.27980659640218,-6.3565864147485,-6.33349783214072,-5.85186882395103,-4.74692152231896,-4.08519569483122,-3.73024545572045,-2.78487668464404,-2.15092471829579,-0.902510956795564,0.496360463886639,0.756812013112905,1.00714394820637,2.37248404949064,2.46618962012525,4.24396641874347,4.33629137438754,4.89477951284853,5.81238911017895,6.14524950944106])\n",
        "y_train = np.array([-1.49888963305016,0.569441996545526,0.623268356304418,0.9063943036413,-0.376423208431739,-0.871911241143502,-0.803958546300539,1.07173322993408,2.29393880644365,2.62802707180373,0.412113574676584,-0.297490218195917,-0.660456836687934,-2.66828227995347,-2.09868165955797,-0.965605061863299,-0.758001691987733,-1.32241178751454,-0.725175367478586,-0.449178680954562])\n",
        "\n",
        "grp = 4\n",
        "#sigmas = np.linspace(0.01,3.,grp)\n",
        "#ls = np.linspace(0.01,10.,grp)\n",
        "\n",
        "sigmas = np.linspace(np.log(0.01),np.log(3.),grp)\n",
        "ls = np.linspace(np.log(0.01),np.log(10.),grp)\n",
        "\n",
        "xx, yy = np.meshgrid(ls,sigmas)\n",
        "\n",
        "sigmas = np.exp(sigmas)\n",
        "ls = np.exp(ls)\n",
        "\n",
        "\n",
        "probabilidades = np.zeros((grp,grp))\n",
        "\n",
        "s = 1.\n",
        "\n",
        "gp_prueba = gaussProcess()\n",
        "gp_prueba.compCov(lambda x,y,sh,lh,sigmah : gp_prueba.Kernels.exponencialCuadrada(x,y,sh,lh)+gp_prueba.Kernels.ruidoBlanco(x,y,sigmah),1.,1.,1.) # Aqui especificamos los hiperparametros\n",
        "funciones = np.asarray([lambda x,y,sh,lh,sigmah: gp_prueba.Kernels.expCua_der_s(x,y,sh,lh) , lambda x,y,sh,lh,sigmah: gp_prueba.Kernels.expCua_der_l(x,y,sh,lh), lambda x,y,sh,lh,sigmah: gp_prueba.Kernels.rB_der_sigma(x,y,sigmah)])\n",
        "gp_prueba.compDerCov( x_train, y_train,funciones, 1.,1.,1.)\n",
        "\n",
        "\n",
        "i = 0\n",
        "for sigma in sigmas:\n",
        "\n",
        "  j = 0\n",
        "  for l in ls:\n",
        "    gp_prueba.Der_Hiper = [s,l,sigma]\n",
        "    gp_prueba.Hiper = [s,l,sigma]\n",
        "    gp_prueba.log_prob_verosimilitud_datos(x_train,y_train)\n",
        "    probabilidades[i,j] = gp_prueba.log_marg_y\n",
        "    resultado = gp_prueba.der_log_prob_ver_hiper(*[s,l,sigma])\n",
        "    print(resultado)\n",
        "\n",
        "    #print(\"logaritmo de la probabilidad de verosimilitud e hiperparametros:\",gp_prueba.log_marg_y)\n",
        "  \n",
        "    j = j + 1\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "\n",
        "fig_3, ax_3 = plt.subplots()\n",
        "\n",
        "plotRange_sig = sigmas\n",
        "plotRange_l = ls\n",
        "\n",
        "heatmap = ax_3.pcolormesh(xx,yy,probabilidades,cmap='RdBu_r',vmin = probabilidades.min(), vmax = probabilidades.max())\n",
        "#ax_3.axis([plotRange_l.min(), plotRange_l.max(), plotRange_sig.min(), plotRange_sig.max()])\n",
        "fig_3.colorbar(heatmap, ax=ax_3)\n",
        "\n",
        "#ax_3.set_xscale('log')\n",
        "#ax_3.set_yscale('log')\n",
        "\n",
        "fig_3.show()\n",
        "\n",
        "#im = ax_3.imshow(probabilidades)\n",
        "\n",
        "#fig_3.colorbar(im, ax=ax_3)\n",
        "\n",
        "#fig_3.show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "\n",
        "busqueda = hybridMontecarlo(gp_prueba.Der_Hiper,1000.,0.1,240,gp_prueba)\n",
        "busqueda.ejecutarTrayectoria()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14.79751764 14.08852872  0.14744661]\n",
            "[ 9.83233548 31.78194653 -0.2975375 ]\n",
            "[  360.75965671 -2310.68448188 56708.47654102]\n",
            "[ 7.42804510e+03 -3.35887661e+03  1.88758487e+07]\n",
            "[14.58227707 13.97229002  0.97267646]\n",
            "[ 9.81389485 30.36043548 -1.6750154 ]\n",
            "[ 13.49014644  -6.90689212 485.85444073]\n",
            "[  302.46217604   -96.09645952 73279.8194554 ]\n",
            "[7.49113805 9.94672281 3.34035856]\n",
            "[ 5.60299677 17.65933024 -0.92587608]\n",
            "[  7.30781226   1.190029   -13.31990394]\n",
            "[  3.01044097  -0.96278645 260.1546236 ]\n",
            "[-1.65103736  0.15560976 -4.95486352]\n",
            "[-1.55738242  0.40164204 -5.01361229]\n",
            "[-1.20614381  0.13370066 -5.19390277]\n",
            "[-7.83669348e-01  4.02722511e-03 -5.18389029e+00]\n",
            "--- 0.4055311679840088 seconds ---\n",
            "se ha mostrado\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAwhLz3iOwtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class hybridMontecarlo():\n",
        "\n",
        "  def __init__(self,x,temp,dt,n,gp):\n",
        "    self.Xo = np.asarray(x) # En este formalismo de procesos gausianos son una lista de hiperparámetros\n",
        "    self.Temp = temp\n",
        "    self.Dt = dt\n",
        "    self.t = 0. # Inicializacion del tiempo\n",
        "    self.N = n\n",
        "    self.Nd = len(self.Xo)\n",
        "    self.GP = gp \n",
        "    self.Fo = np.asarray(self.GP.der_log_prob_ver_hiper(*self.Xo))\n",
        "    self.Po = (0.5/self.Temp)*np.random.randn(len(self.Xo))\n",
        "    self.trayectoria, self.ax_tray = plt.subplots(1,1)\n",
        "\n",
        "  def updateStepIter(self):\n",
        "    '''\n",
        "    Ejecuta avance en el integrador simpléctico y actualiza las fuerzas calculadas\n",
        "    '''\n",
        "    self.update_x_verlet()\n",
        "    self.F = self.GP.der_log_prob_ver_hiper(*self.X)\n",
        "    self.update_p_verlet()\n",
        "    self.Fo = self.F\n",
        "    self.t += self.Dt\n",
        "\n",
        "  def update_x_verlet(self):\n",
        "    '''\n",
        "    La operacion se realiza sobre ndarray\n",
        "    '''\n",
        "    self.X = self.Xo + self.Dt*(self.Po + (0.5*self.Dt*self.Fo))\n",
        "    self.Xo = self.X\n",
        "\n",
        "  def update_p_verlet(self):\n",
        "    '''\n",
        "    La operacion se realiza sobre ndarray\n",
        "    '''\n",
        "    self.P = self.Po + 0.5*self.Dt*(self.Fo + self.F)\n",
        "    self.Po = self.P\n",
        "\n",
        "  #@numba.njit\n",
        "  def ejecutarTrayectoria(self):\n",
        "    '''\n",
        "    Desarrolla una trayectoria en el integrador simplectico de self.N iteraciones\n",
        "    '''\n",
        "    for index_t in range(self.N):\n",
        "      self.updateStepIter()\n",
        "      self.ploteado(False)\n",
        "    self.ploteado(True)\n",
        "\n",
        "\n",
        "  def ploteado(self,mostrar):\n",
        "    '''\n",
        "    Muestra punto x integrado hasta ahora frente al indice del tiempo\n",
        "    '''\n",
        "    for i in range(self.Nd):\n",
        "      self.ax_tray.plot(self.t,self.X[i],'ob')\n",
        "    if mostrar == True:\n",
        "      print(\"se ha mostrado\")\n",
        "      self.trayectoria.show()"
      ],
      "execution_count": 95,
      "outputs": []
    }
  ]
}