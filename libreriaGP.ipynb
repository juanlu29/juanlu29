{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMqfNyZZZSJEw0xVPKvpmzR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanlu29/juanlu29/blob/gp_aprendizaje/libreriaGP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juguGpOpG3HF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5c776e9a-b189-4f66-c5b8-1b0c6a3bdaf1"
      },
      "source": [
        "# Modulos y constantes\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import scipy\n",
        "import scipy.linalg\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numba"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djR_jiyCGlbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class gaussProcess():\n",
        "  def __init__(self,dominio,observacion,*hiper):\n",
        "    '''\n",
        "    Los objetos de esta clase modelan procesos gaussianos caracterizados por su promedio y covarianza\n",
        "    Como argumento inicial incluimos el data set sobre el que se va a trabajar, su dominio y las observaciones como ndarrays\n",
        "    '''\n",
        "    #self.Derivadas = prior_Partial_Der\n",
        "    self.Kernels = self.kernels()\n",
        "    self.Dominio = dominio\n",
        "    self.Observacion = observacion\n",
        "    self.Hiper = hiper\n",
        "    # Se crean matrices [[x],[x],...] (longitud de la concatenacion nx) y [[y],[y],...].T (longitud de la concatenacion ny)\n",
        "    # Son necesarios para devolver los resultados necesarios en los calculos matriciales\n",
        "    self.xM = np.full((len(self.Observacion),len(self.Dominio)),self.Dominio)\n",
        "    self.yM = (np.full((len(self.Dominio),len(self.Observacion)),self.Observacion))\n",
        "\n",
        "  def calcCovM(self,xM,yM):\n",
        "    '''\n",
        "    Dados x e y como ndarrays, calcula la matriz de covarianzas cuyos elementos son evaluados de la forma\n",
        "    C(xi,yi) = (k(xi,yi)) con rango (nx x ny) donde nx y ny son la longitud de los vectores x  e y respectivamente.\n",
        "    hiper son los hiperparámetros usados en el modelo\n",
        "    '''\n",
        "    # Llamamos la funcion Ker que nos debe devolver como salida una matriz cuyos elementos calculados representan k(x,y)\n",
        "    return self.Ker(xM,yM.T,*self.Hiper)\n",
        "\n",
        "  def calcDerCovM(self,xM,yM):\n",
        "    '''\n",
        "    Dados x e y como ndarrays, calcula la matriz correspondiente a la derivada respecto los hiperparámetros de las covarianzas\n",
        "    cuyos elementos son evaluados de la forma C_j(xi,yi) = (dk(xi,yi)dh_j) con rango (nx x ny) donde nx y ny son la longitud de los \n",
        "    vectores x e y respectivamente. Hiper son los hiperparámetros usados en el modelo\n",
        "    '''\n",
        "    # Generamos el array de matrices llamando al zip de las funciones de derivadas y sus hiperparámetros para generarlas\n",
        "    return np.asarray([ self.DerKer[i](xM,yM.T,*self.Hiper) for i in range(len(self.DerKer)) ] )\n",
        "\n",
        "  def compCov(self,covarianza):\n",
        "    '''\n",
        "    Permite definir el kernel a usar por el proceso gaussiano, tanto si es uno de los kernels definidos en la clase como si es una combinacion de los mismos\n",
        "    El argumento es una funcion anónima en caso de ser una composición, en caso contrario es suficiente con proporcionar el nombre del kernel definido\n",
        "    hiper son los hiperparámetros que precisan el kernel y vienen dado por un diccionario\n",
        "    '''\n",
        "    self.Ker = covarianza # Covarianza definida\n",
        "    self.Ker = np.vectorize(self.Ker)\n",
        "\n",
        "  def compDerCov(self,derCovarianza):\n",
        "    '''\n",
        "    Permite definir la expresion para la derivada del kernel respecto los distintos hiperparametros como un iterable zip\n",
        "    de funciones anonimas juntos a sus hiperparámetros. \n",
        "    En este caso por propositos de optimizacion se espera que se evalue dinamicamente con distintos hiperparámetros.\n",
        "    Los datos contenidos en *hiper están encapsulados en una tupla a la que se debe acceder previamente\n",
        "    '''\n",
        "    try:\n",
        "      self.DerKer = derCovarianza\n",
        "    except:\n",
        "      raise NameError(\"No se ha definido kernel previamente\")\n",
        "\n",
        "\n",
        "  class kernels():\n",
        "    '''\n",
        "    Se definen kernels de uso común junto a sus hiperparámetros y derivadas asociadas\n",
        "    '''\n",
        "    def __init__(self):\n",
        "      return\n",
        "\n",
        "    def exponencialCuadrada(self,xb,xa,s,l):\n",
        "      '''\n",
        "      Correlacion estacionaria (depende solo de la distancia r = abs(xb-xa)) con decaimiento exponencial cuadratico\n",
        "\n",
        "      k(xb,xa) = s² exp( - (xb-xa)²/(2 l²) )\n",
        "\n",
        "      Hiperparámetros:\n",
        "      s : amplitud de la correlacion, esta relacionado con la amplitud de las trayectorias generadas por el GP\n",
        "      l : escala de longitud del GP. Esta relacionada con la distancia sobr la cual los procesos generados por el GP pueden presentar oscilaciones o variaciones\n",
        "      '''\n",
        "      return np.power(s,2)*np.exp(-np.power(xa-xb,2)/(2.*np.power(l,2)))\n",
        "\n",
        "    def expCua_der_s(self,xb,xa,s,l):\n",
        "      '''\n",
        "      Derivada respecto el hiperparámetro s de las correlaciones estacionarias con decaimiento exponenciales cuadráticas\n",
        "\n",
        "      k(xb,xa) = 2s exp( - (xb-xa)²/(2 l²) )\n",
        "\n",
        "      Hiperparámetros:\n",
        "      s : amplitud de la correlacion, esta relacionado con la amplitud de las trayectorias generadas por el GP\n",
        "      l : escala de longitud del GP. Esta relacionada con la distancia sobr la cual los procesos generados por el GP pueden presentar oscilaciones o variaciones\n",
        "      '''\n",
        "      return 2*s*np.exp(-np.power(xa-xb,2)/(2.*np.power(l,2)))\n",
        "\n",
        "    def expCua_der_l(self,xb,xa,s,l):\n",
        "      '''\n",
        "      Derivada respecto el hiperparámetro l de las correlaciones estacionarias con decaimiento exponenciales cuadráticas\n",
        "\n",
        "      k(xb,xa) = s²(xb-xa)² / l³ exp( - (xb-xa)²/(2 l²) )\n",
        "\n",
        "      Hiperparámetros:\n",
        "      s : amplitud de la correlacion, esta relacionado con la amplitud de las trayectorias generadas por el GP\n",
        "      l : escala de longitud del GP. Esta relacionada con la distancia sobr la cual los procesos generados por el GP pueden presentar oscilaciones o variaciones\n",
        "      '''\n",
        "      return (np.power(s*(xa-xb),2)/np.power(l,3))*np.exp(-np.power(xa-xb,2)/(2.*np.power(l,2)))\n",
        "\n",
        "    def ruidoBlanco(self,xb,xa,sigma):\n",
        "      '''\n",
        "      Correlaciones de ruido blanco o gaussiano puro, solo correlaciona los puntos consigo mismo. \n",
        "\n",
        "      k(xb,xa) = sigma² delta(xb,xa)\n",
        "\n",
        "      Representa incertidumbres intrínsecas en las observaciones y asume una distribución a priori de esos errores gaussiano\n",
        "      Hiperparáámetros:\n",
        "      s : amplitud o incertidumbre del ruido generado\n",
        "      '''\n",
        "      return np.where(xb==xa, np.power(sigma,2),0.) # Se usa el metodo numpy.where porque las operaciones logicas sobre arrays son consideradas ambiguas en el intérprete de python\n",
        "                                                    # Esta manera es válidad para python para comprar elemento a elemento entre matrices.\n",
        "\n",
        "    def rB_der_sigma(self,xb,xa,sigma):\n",
        "      '''\n",
        "      Derivada respecto el hiperparámetro sigma del ruido no correlacionado\n",
        "\n",
        "      k(xb,xa) = sigma² delta(xb,xa)\n",
        "\n",
        "      Representa incertidumbres intrínsecas en las observaciones y asume una distribución a priori de esos errores gaussiano\n",
        "      Hiperparáámetros:\n",
        "      s : amplitud o incertidumbre del ruido generado\n",
        "      '''\n",
        "      return np.where(xb==xa, 2*sigma,0.) # Se usa el metodo numpy.where porque las operaciones logicas sobre arrays son consideradas ambiguas en el intérprete de python\n",
        "                                          # Esta manera es válidad para python para comprar elemento a elemento entre matrices.\n",
        "\n",
        " \n",
        "  def cholDescomp(self,K):\n",
        "    '''\n",
        "    Descomposicion cholesky de una matriz dada\n",
        "    '''\n",
        "    try:\n",
        "      L = scipy.linalg.cholesky(K, lower=True)\n",
        "    except:\n",
        "     # L = scipy.linalg.cholesky(K + np.diag(0.000001*np.ones(int(np.sqrt(K.size)))), lower=True)\n",
        "      raise NameError(\"No es posible efectuar descomposicion cholesky\")\n",
        "\n",
        "    return L\n",
        "\n",
        "  def calcInvK(self,matriz):\n",
        "    '''\n",
        "    Calculo de la inversa de matriz. \n",
        "    '''\n",
        "    # Calculo de matriz inversa de la covarianza. \n",
        "    try:\n",
        "      invK = np.linalg.inv(matriz)\n",
        "    except:\n",
        "      raise NameError(\"No es posible calcular matriz inversa\")\n",
        "\n",
        "    return invK\n",
        "\n",
        "  def condicionarGP(self,*dominio_test):\n",
        "    '''\n",
        "    Dadas unas observaciones junto a sus valores de dominio (uni-dimensionales) en el rango sobre el que se modela el GP, \n",
        "    obtiene la covarianza asociada a la distribución de trayectorias condicionadas al conjunto de partida dado un dominio \n",
        "    de test en el que queremos comprobar la predicción. Por tanto permite generar las trayectorias compatibles con los datos\n",
        "\n",
        "    También calcula el logaritmo de la probabilidad de verosimilitud marginal (marginal likelihood) de las observaciones dados los inputs \n",
        "    y parámetros del modelo usado.\n",
        "\n",
        "    Este algoritmo esta especificado en el libro \"Gaussian Processes for Machine Learning\", como algoritmo 2.1\n",
        "    '''\n",
        "    self.xtest = np.reshape(dominio_test,(len(dominio_test),1))\n",
        "\n",
        "    # Definimos nueva covarianza\n",
        "    # Primero se realiza la descomposición cholesky de la adición de la covarianza de la distribución a priori,\n",
        "    # para lo cual calculamos la matriz de covarianza asociada al dominio de las observaciones sobre si mismo\n",
        "    # y al cruce del dominio de las observaciones y del test de prediccion.\n",
        "    try:\n",
        "      self.Cov_obs_obs = self.calcCovM(self.xM,self.xM,*self.Hiper)\n",
        "      self.Cov_obs_test = self.calcCovM(self.xM,self.xtest,*self.Hiper)\n",
        "    except:\n",
        "      raise NameError(\"Debes especificar primero el kernel que estas usando junto a sus hiperparametros con el metodo self.compCov\")\n",
        "\n",
        "    cholL = np.linalg.cholesky(self.Cov_obs_obs)\n",
        "\n",
        "    # Calculo del vector alfa como solucion del sistema K_obs_obs*alfa = y_entrenamiento usando la descomposición cholesky anterior\n",
        "    self.Alfa = scipy.linalg.cho_solve((cholL,True),self.yM)\n",
        "\n",
        "    # Vector v solución particular del sistema cholL*v = k_test para todos los datos del entrenamiento.\n",
        "    # Este sistema se resuelve introduciendo k_star no como matriz columna sino como la submatriz calculada como la evaluación de la covarianza a priori de los inputs de los valores a predecir y los inputs del entrenamiento\n",
        "    v = scipy.linalg.solve_triangular(cholL,self.cov_obs_test, lower=True)\n",
        "\n",
        "    # Se obtiene el valor promedio del proceso predictivo condicionado a las observaciones\n",
        "    self.Media_pred = np.matmul(self.Cov_obs_test.T,self.Alfa)\n",
        "\n",
        "    # Covarianza predictiva o condicionada. El proceso llevado a cabo ha sido obtener la distribución condicionada del GP a las observaciones\n",
        "    # Intenta calcular directamente la matriz, en caso contrario calcular la matriz de covarianza de la distribucion a priori dado el test\n",
        "    try:\n",
        "      self.Cov_pred = self.Cov_priori - np.matmul(v.T,v)\n",
        "    except:\n",
        "      # En caso que no esté definida o no coincida con la dimensionalidad del test, se recalcula la covarianza a priori\n",
        "      self.Cov_priori = self.calcCovM(self.xtest,self.xtest,*self.Hiper)\n",
        "      self.Cov_pred = self.Cov_priori - np.matmul(v.T,v)\n",
        "\n",
        "    # La siguiente matriz descompuesta es necesaria para generar procesos del GP.\n",
        "    self.L_pred = self.cholDescomp(self.Cov_pred)\n",
        "  \n",
        "\n",
        "  def log_prob_verosimilitud_datos(self,*hiper):\n",
        "    '''\n",
        "    Dadas unas observaciones, kernel e hiperparámetros dados, calcula el logaritmo de la probabilidad de verosimilitud de las observaciones al modelo y sus parámetros\n",
        "    '''\n",
        "\n",
        "    # Actualizamos hiperparámetros\n",
        "    self.Hiper = hiper\n",
        "\n",
        "    # Primero se realiza la descomposición cholesky de la adición de la covarianza de la distribución a priorir y el término de ruido.\n",
        "    #cholL = np.linalg.cholesky(self.calcCovM(dominio,dominio,*self.Hiper))\n",
        "    cholL = np.linalg.cholesky(self.calcCovM(self.xM,self.xM))\n",
        "\n",
        "    # Calculo del vector alfa como solucion del sistema K*alfa = y_entrenamiento usando la descomposición cholesky anterior\n",
        "    alfa = scipy.linalg.cho_solve((cholL,True),self.Observacion)\n",
        "\n",
        "    # Calculo de la probabilidad de verosimilitud marginal a este modelo y sus parámetros\n",
        "    self.log_marg_y = +1.*( 0.5*np.dot(alfa,self.Observacion) + np.sum(np.log(np.diag(cholL)),axis=0) + (float(len(self.Dominio))/2.)*np.log(2*np.pi))\n",
        "    if (self.log_marg_y > +90.):\n",
        "      self.log_marg_y = 90.\n",
        "    return self.log_marg_y\n",
        "\n",
        "  def der_log_prob_ver_hiper(self,*hiper):\n",
        "    '''\n",
        "    Derivada del logaritmo de la probabilidad de verosimilitud respecto hiperapametros,\n",
        "    devuelve un ndarray con cada componenete correspondiendo a la matriz del modelo respecto\n",
        "    los distintos. La expresion es la siguiente\n",
        "\n",
        "    1/2 traza[  {alfa*alfa.T - K⁻¹} dK/dh] ; alfa = K⁻¹\\y\n",
        "\n",
        "    '''\n",
        "\n",
        "    # Actualizamos hiperparámetros\n",
        "    self.Hiper = hiper\n",
        "\n",
        "    # Definimos nueva covarianza\n",
        "    try:\n",
        "      covDom = self.calcCovM(self.xM,self.xM)\n",
        "    except:\n",
        "      raise NameError(\"Debes especificar primero el kernel que estas usando junto a sus hiperparametros con el metodo self.compCov\")\n",
        "\n",
        "\n",
        "    invCovDom = self.calcInvK(covDom)\n",
        "\n",
        "    cholL = np.linalg.cholesky(covDom)\n",
        "\n",
        "    # Calculo del vector alfa como solucion del sistema K_obs_obs*alfa = y_entrenamiento usando la descomposición cholesky anterior\n",
        "    alfa = scipy.linalg.cho_solve((cholL,True),self.Observacion)\n",
        "\n",
        "    alfa = np.reshape(alfa,(len(alfa),1))\n",
        "\n",
        "    self.Der_Hiper = hiper\n",
        "    derCovHiper = self.calcDerCovM(self.xM,self.xM)\n",
        "    return -0.5*np.trace(np.matmul(np.matmul(alfa,alfa.T)-invCovDom,derCovHiper),axis1=1,axis2=2) # La suma de la traza en un array de mas de 2 dimensiones debe especificarse sobre sus indices. En este caso es dimensióón 3.\n",
        "    \n",
        "\n",
        "  def prioriGP(self,*dominio):\n",
        "    '''\n",
        "    Computa los términos necesarios para extraer realizaciones del GP siguiendo la distribución a priori\n",
        "    '''\n",
        "\n",
        "    self.xtest = np.reshape(dominio_test,(len(dominio_test),1))\n",
        "\n",
        "    try:\n",
        "      self.Cov_priori = self.calcCovM(self.xtest,self.xtest,*self.Hiper)\n",
        "    except:\n",
        "      raise NameError(\"Debes especificar primero el kernel que estas usando junto a sus hiperparametros con el metodo self.compCov\")\n",
        "\n",
        "    # La siguiente matriz descompuesta es necesaria para generar procesos del GP.\n",
        "    self.L_priori = self.cholDescomp(self.Cov_pred)\n",
        "\n",
        "\n",
        "  def procesosPrioriGP(self):\n",
        "    '''\n",
        "    Genera realizaciones del proceso gaussiano dada la descomposicion cholesky de la matriz de covarianzas y la media correspondiente\n",
        "    '''\n",
        "    # Si no se ha calculado la descomposicióón de la covarianza se llama al método aqui\n",
        "    try:\n",
        "      return self.Mean_priori +  np.matmul(self.L_priori,(np.randn(len(self.xtest))).T)\n",
        "    except:\n",
        "      raise NameError(\"No se ha incluido los valores del dominio sobre los que muestrear el proceso o no se ha calculado la descomposición de la covarianza\")\n",
        "\n",
        "  def procesosCondicionadosGP(self):\n",
        "    '''\n",
        "    Genera realizaciones del proceso gaussiano dada la descomposicion cholesky de la matriz de covarianzas y la media correspondiente\n",
        "    '''\n",
        "    try:\n",
        "      return self.Media_pred + np.matmul(self.L_pred,(np.randn(len(self.xtest))).T)\n",
        "    except:\n",
        "      raise NameError(\"El GP no ha sido condicionado a las observaciones\")\n",
        "\n",
        "  def sigmaCalc(self,cov):\n",
        "    '''\n",
        "    Desviacion estándar punto a punto del proceso gausiano dado por la matriz de covarianza \n",
        "    Es la raiz cuadrado de los elementos de la diagonal de la matriz de covarianzas del proceso generado\n",
        "    '''\n",
        "    return np.sqrt(np.diag(cov))\n",
        "\n",
        "\n",
        "  def correlacionPuntoPunto(self):\n",
        "    '''\n",
        "    Obtiene la correlacion punto a punto dado un inputo concreto por el indice i_x\n",
        "    '''\n",
        "    try:\n",
        "      self.corrPP_pred = np.array([ self.K_pred[i,:] for i in range(len(self.K_pred)) ])\n",
        "    except:\n",
        "      print(\" Proceso gaussiano no entrenado aún, no existe K_pred \")\n",
        "    self.corrPP_prior = np.array([ self.K_prior[i,:] for i in range(len(self.K_prior)) ])\n",
        "\n",
        "  \n",
        "  def derivada_LO_CV(self,*args):\n",
        "    '''\n",
        "    Dadas unas observaciones particulares estima la derivada de la suma de los logaritmos de la evaluación de la distribución de probabilidad marginal de verosimilitud a que subconjuntos\n",
        "    de las observaciones están condicionadas al resto, respecto a los hiperparámetros del modelo. Si se encuentra el máximo de este valor, estamos asegurándonos de que con los hiperparámetros ajustados\n",
        "    las \"predicciones\" tras generar trayectorias del proceso gausiano que corresponderían a los subconjuntos excluidos sucesivamente son las más probables que el modelo puede hacer. Al ser la suma, esta optimización \n",
        "    es global y abarca la aproximación de observacion/test de todos los subconjuntos.\n",
        "    '''\n",
        "\n",
        "    if not isinstance(args[0], np.ndarray):\n",
        "      raise NameError(\"Las observaciones dadas para calcular la derivada del logaritmo de la distribución marginal de verosimilitud no es un array con datos\")\n",
        "    else:\n",
        "      observaciones = args[0]\n",
        "\n",
        "    # Vector auxiliar alpha y matriz auxiliar Z y la diagonal de la inversa de la distribucion a priori\n",
        "    try:\n",
        "      alpha = np.matmul(self.invK,observaciones)\n",
        "      invK_diag = np.diag(self.invK)\n",
        "      zeta = [np.matmul(self.invK,self.Derivadas[i]) for i in range(len(self.Derivadas)) ] # Es una lista de matrices\n",
        "      zeta_K = [np.diag(np.matmul(zeta[i],self.invK)) for i in range(len(self.Derivadas)) ]\n",
        "      alpha_invK = np.multiply(alpha,1./invK_diag)\n",
        "    except:\n",
        "      raise NameError(\"Necesitas calcular la matriz inversa de covarianzas de la distribución a priori\")\n",
        "    \n",
        "    termino_1 = [np.matmul(np.matmul(alpha_invK,zeta[i]),alpha) for i in range(len(self.Derivadas)) ] # Debido a Z esto es una lista\n",
        "    termino_2 = [np.sum(np.multiply(np.multiply(0.5*(1. + np.multiply(np.power(alpha,2),1./invK_diag)),zeta_K[i]),1./invK_diag)) for i in range(len(self.Derivadas)) ] # Debido a zeta_K esto es una lista\n",
        "\n",
        "    # Calculo. Es el valor de la derivada del logaritmo\n",
        "    self.derVerLOO = np.asarray([ termino_1[i] + termino_2[i] for i in range(len(self.Derivadas))])\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SciOihGB3HVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a8a4cf6-3686-4bf6-dd37-67812754d5a2"
      },
      "source": [
        "import time\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "#x_train = np.linspace(0.1,9.7,5)\n",
        "#y_train = 1.1*np.sin(2.*x_train) + np.asarray([random.gauss(0.,1.) for i in range(len(x_train))])\n",
        "x_train = np.array([-7.27980659640218,-6.3565864147485,-6.33349783214072,-5.85186882395103,-4.74692152231896,-4.08519569483122,-3.73024545572045,-2.78487668464404,-2.15092471829579,-0.902510956795564,0.496360463886639,0.756812013112905,1.00714394820637,2.37248404949064,2.46618962012525,4.24396641874347,4.33629137438754,4.89477951284853,5.81238911017895,6.14524950944106])\n",
        "y_train = np.array([-1.49888963305016,0.569441996545526,0.623268356304418,0.9063943036413,-0.376423208431739,-0.871911241143502,-0.803958546300539,1.07173322993408,2.29393880644365,2.62802707180373,0.412113574676584,-0.297490218195917,-0.660456836687934,-2.66828227995347,-2.09868165955797,-0.965605061863299,-0.758001691987733,-1.32241178751454,-0.725175367478586,-0.449178680954562])\n",
        "\n",
        "grp = 4\n",
        "#sigmas = np.linspace(0.01,3.,grp)\n",
        "#ls = np.linspace(0.01,10.,grp)\n",
        "\n",
        "sigmas = np.linspace(np.log(0.01),np.log(3.),grp)\n",
        "ls = np.linspace(np.log(0.01),np.log(10.),grp)\n",
        "\n",
        "xx, yy = np.meshgrid(ls,sigmas)\n",
        "\n",
        "sigmas = np.exp(sigmas)\n",
        "ls = np.exp(ls)\n",
        "\n",
        "\n",
        "probabilidades = np.zeros((grp,grp))\n",
        "\n",
        "s = 1.\n",
        "\n",
        "gp_prueba = gaussProcess(x_train,y_train,[0.,0.])\n",
        "\n",
        "gp_prueba.compCov(lambda x,y,lh,sigmah : gp_prueba.Kernels.exponencialCuadrada(x,y,1.,lh)+gp_prueba.Kernels.ruidoBlanco(x,y,sigmah)) # Aqui especificamos los hiperparametros\n",
        "funciones = np.asarray([lambda x,y,lh,sigmah: gp_prueba.Kernels.expCua_der_l(x,y,1.,lh), lambda x,y,lh,sigmah: gp_prueba.Kernels.rB_der_sigma(x,y,sigmah)])\n",
        "\n",
        "#gp_prueba.compCov(lambda x,y,sh,lh,sigmah : gp_prueba.Kernels.exponencialCuadrada(x,y,sh,lh)+gp_prueba.Kernels.ruidoBlanco(x,y,sigmah)) # Aqui especificamos los hiperparametros\n",
        "#funciones = np.asarray([lambda x,y,sh,lh,sigmah: gp_prueba.Kernels.expCua_der_s(x,y,sh,lh) , lambda x,y,sh,lh,sigmah: gp_prueba.Kernels.expCua_der_l(x,y,sh,lh), lambda x,y,sh,lh,sigmah: gp_prueba.Kernels.rB_der_sigma(x,y,sigmah)])\n",
        "gp_prueba.compDerCov(funciones)\n",
        "\n",
        "\n",
        "i = 0\n",
        "for sigma in sigmas:\n",
        "\n",
        "  j = 0\n",
        "  for l in ls:\n",
        "    #gp_prueba.Hiper = [s,l,sigma]\n",
        "    gp_prueba.Hiper = [l,sigma]\n",
        "    gp_prueba.log_prob_verosimilitud_datos(*gp_prueba.Hiper)\n",
        "    probabilidades[i,j] = gp_prueba.log_marg_y\n",
        "    resultado = gp_prueba.der_log_prob_ver_hiper(*gp_prueba.Hiper)\n",
        "    #print(\"logaritmo de la probabilidad de verosimilitud e hiperparametros:\",gp_prueba.log_marg_y)\n",
        "  \n",
        "    j = j + 1\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "\n",
        "#fig_3, ax_3 = plt.subplots()\n",
        "\n",
        "plotRange_sig = sigmas\n",
        "plotRange_l = ls\n",
        "\n",
        "#heatmap = ax_3.pcolormesh(xx,yy,probabilidades,cmap='RdBu_r',vmin = probabilidades.min(), vmax = probabilidades.max())\n",
        "#ax_3.axis([plotRange_l.min(), plotRange_l.max(), plotRange_sig.min(), plotRange_sig.max()])\n",
        "#fig_3.colorbar(heatmap, ax=ax_3)\n",
        "\n",
        "#ax_3.set_xscale('log')\n",
        "#ax_3.set_yscale('log')\n",
        "\n",
        "#fig_3.show()\n",
        "\n",
        "#im = ax_3.imshow(probabilidades)\n",
        "\n",
        "#fig_3.colorbar(im, ax=ax_3)\n",
        "\n",
        "#fig_3.show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "print(\"partida :\",[1.,0.3],gp_prueba.log_prob_verosimilitud_datos(*[1.1,0.15]))\n",
        "ppp = pruebaHMC()\n",
        "afdaf = [np.random.randn(),np.random.randn(),np.random.randn(),np.random.randn(),np.random.randn()]\n",
        "#afdaf = [10485.50142632,   9058.50096209 , -8420.49975872, -10909.50244681 ,-311.49708436]\n",
        "#print(\"partida :\",afdaf)\n",
        "\n",
        "\n",
        "# Correlcion a T = 20\n",
        "#correlando = hmc_annealing([1.,0.3],200,.01,1,gp_prueba)\n",
        "correlando = hmc_annealing(afdaf,0.5,.4,4,ppp)\n",
        "acc_aver = correlando.aceptacionFrenteTemperatura(np.linspace(0.5,20,40),20000)\n",
        "#correlando.correlacionExploracion(10000)\n",
        "#dat = correlando.Corr[0:100]\n",
        "#print(dat)\n",
        "#plt.plot(dat,'o')\n",
        "\n",
        "plt.plot(np.linspace(0.5,20,40),acc_aver,'-o')\n",
        "temp_t = [0.104999053136439,0.284716517883025,0.443330795481337,0.609478683975592,0.554837313380923,0.709404234851678,0.814066141318422,0.897934291533495,1.00467557362541,1.09616810113276,1.20290938322467,1.29440191073202,1.40114319282393,1.52218018233887,1.6374988888846,1.70611828451511,1.79761081202246,1.90435209411437,1.99584462162173,2.11688161113666,2.26422270230996,2.39231224082026,2.36943910894342,2.52573884343514,2.6200905124271,2.7674316036004,2.89200219874503,3.00353315375132,3.11880647709888,3.27388086524006,3.40127150249856,3.51976703291607,3.66812470772834,3.71426196518931,3.83331954906106,3.93243645386069,4.10017275429084,4.26960336078594,4.44041059095881,4.60991683611752,4.74729177697305,4.89490196381549,5.0760930477026,5.24586251541069,5.41156564856289,5.58090708105457,5.7425533216042,5.90784329776944,6.00626707736069,6.09775960486804,6.20450088695995,6.29853487356473,6.42751392275912,6.58331205348162,6.75236685524803,6.91958722037268,7.09316441802674,7.25835925935946,7.4193183355298,7.57790538320921,7.71233361970367,7.86661513667686,8.01910268252244,8.09534645544524,8.21638344496017,8.37490695616215,8.53756033839744,8.71183181936383,8.86693343742391,9.00488981713598,9.16275927636435,9.3304955767945,9.51168666068161,9.66692122481633,9.82862155989008,9.86038979860792,10.0090651558074,10.1072290134455,10.2712264365496,10.4226876239135,10.5961422073129,10.5961422073129,10.7577790059092,10.8820563557734,11.0087057341284,11.180677799721,11.3433311819563,11.5093731763215,11.6788037828166,11.8524049888561,12.0012060226044,12.182012684107,12.3497489845371,12.5174852849673,12.6828138873051,12.8529578858276,13.0267936880915,13.1884304866879,13.3476952567933,13.4149834119442,13.5669583946104,13.737385651732,13.9152877885518,14.0834150826893,14.2511513831194,14.4051205893295,14.5783544670704,14.7692180452871,14.7228364167591,14.9099346226815,15.0923464162456,15.2419294374085,15.4096657378386,15.5856952205867,15.7330664079861,15.7540334455399,15.9103331800316,16.0399475940004]\n",
        "h_aver_t = [-0.0000293439022640562,-0.000178619663102952,0.00507715690353194,0.0211502880040338,0.00781521894818227,0.0323156050184674,0.0419912187563756,0.0648357858948734,0.0801556012076392,0.0978841447131789,0.118738660133355,0.135305921571973,0.156242322266098,0.178510697759225,0.184893538878787,0.206129096023144,0.218736087848928,0.231848722822962,0.248371319566699,0.268706085977243,0.276696803603057,0.296684044524625,0.279689963212794,0.296450266601451,0.314041920092589,0.321551561733949,0.334326155531913,0.346537056861613,0.35741462131818,0.361982349635211,0.370913429164186,0.385924815041377,0.387048732954098,0.397876900883253,0.397936172688544,0.406860282057804,0.412016546032197,0.4159049797768,0.420497966547163,0.42819484262863,0.437529135055533,0.44382590146168,0.446525441276908,0.448874561292229,0.452676921174917,0.458458708397394,0.462676734802648,0.469519724557002,0.481977581008753,0.468150517580452,0.487017454078397,0.474044510151861,0.481133113024566,0.481503989401825,0.487846080872667,0.486792706155169,0.489744294856544,0.492986379513231,0.494323421442434,0.491468023947409,0.503109816795679,0.500825158587954,0.500492050221405,0.512712504751957,0.500290370039242,0.504082011976769,0.506205090677325,0.505777603816156,0.51334656290474,0.519164436160506,0.518688379434094,0.519664878723664,0.518134409200106,0.515256535373149,0.519731621396073,0.513157985526256,0.514651057950552,0.527089941396645,0.524811637551915,0.530548312588894,0.532799381352761,0.522015675668416,0.527807251757051,0.526201857325675,0.530325615959649,0.524577056660002,0.531537478757706,0.534155944629649,0.531817269151667,0.530838614977929,0.534504522055639,0.536131372561705,0.537059485098486,0.538263029920371,0.539592233126439,0.54075200483809,0.539319365559549,0.541677715434953,0.546772857022618,0.538348304963286,0.543910266923076,0.544426884342911,0.543806994050662,0.547046032173077,0.54499907519374,0.547390338567547,0.55078725203533,0.54813679306709,0.54331895317853,0.548871701409877,0.546779737683234,0.551750561532614,0.551400519384201,0.551723788576413,0.558998583589866,0.549484114011763,0.55359314257521,0.560466773406837]\n",
        "plt.plot(temp_t,h_aver_t,'-v')\n",
        "\n",
        "\n",
        "#busqueda = hmc_annealing([1.,0.3],400.,.4,1,gp_prueba)\n",
        "#busqueda = hmc_annealing(afdaf,400.,0.4,10,ppp)\n",
        "#busqueda.annealing()\n",
        "#print(\"Finalmente el valor minimo calculado :\",gp_prueba.log_prob_verosimilitud_datos(busqueda.ObjetoHMC.Xo), \" teorico :\", [1.1,0.15])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 0.37076449394226074 seconds ---\n",
            "partida : [1.0, 0.3] 21.388132887471357\n",
            "tempratura : 0  prob media : 0.005736532089414751\n",
            "tempratura : 1  prob media : 0.045841922732885086\n",
            "tempratura : 2  prob media : 0.11763812499929396\n",
            "tempratura : 3  prob media : 0.1803812700730387\n",
            "tempratura : 4  prob media : 0.23970003729770673\n",
            "tempratura : 5  prob media : 0.2868995466684741\n",
            "tempratura : 6  prob media : 0.32076314920865956\n",
            "tempratura : 7  prob media : 0.3501485254846916\n",
            "tempratura : 8  prob media : 0.3832913381217911\n",
            "tempratura : 9  prob media : 0.39871724714396894\n",
            "tempratura : 10  prob media : 0.41259055017574603\n",
            "tempratura : 11  prob media : 0.4286230982824931\n",
            "tempratura : 12  prob media : 0.43615731834475724\n",
            "tempratura : 13  prob media : 0.4504670074839304\n",
            "tempratura : 14  prob media : 0.4609635610764885\n",
            "tempratura : 15  prob media : 0.46625503580524946\n",
            "tempratura : 16  prob media : 0.4721177382268205\n",
            "tempratura : 17  prob media : 0.47742399966203714\n",
            "tempratura : 18  prob media : 0.4879420287752552\n",
            "tempratura : 19  prob media : 0.4917672361210635\n",
            "tempratura : 20  prob media : 0.4958911517228826\n",
            "tempratura : 21  prob media : 0.5002741322851708\n",
            "tempratura : 22  prob media : 0.5024579812011369\n",
            "tempratura : 23  prob media : 0.5009459079366017\n",
            "tempratura : 24  prob media : 0.5045415546013282\n",
            "tempratura : 25  prob media : 0.5085791520283313\n",
            "tempratura : 26  prob media : 0.5099880803592328\n",
            "tempratura : 27  prob media : 0.5177939574764918\n",
            "tempratura : 28  prob media : 0.5203989025405837\n",
            "tempratura : 29  prob media : 0.5214248686092647\n",
            "tempratura : 30  prob media : 0.522362638398957\n",
            "tempratura : 31  prob media : 0.5305431643160329\n",
            "tempratura : 32  prob media : 0.5285226139488066\n",
            "tempratura : 33  prob media : 0.524285720631469\n",
            "tempratura : 34  prob media : 0.5293700118367566\n",
            "tempratura : 35  prob media : 0.530547585680454\n",
            "tempratura : 36  prob media : 0.5338821830739257\n",
            "tempratura : 37  prob media : 0.5402623913267949\n",
            "tempratura : 38  prob media : 0.5338529254897817\n",
            "tempratura : 39  prob media : 0.5321996019291226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6a7bdad630>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZN7UHKsWhBv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAwhLz3iOwtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class hmc_annealing():\n",
        "\n",
        "  def __init__(self,x,temp,dt,n,gp):\n",
        "    self.Dt = dt\n",
        "    self.N = n\n",
        "    self.GP = gp\n",
        "    # Inicializacion de contadores\n",
        "    self.inicializarContadores(temp)\n",
        "    self.ObjetoHMC = self.hybridMontecarlo(x,self.Temp,self.Dt,self.N,self.GP)\n",
        "\n",
        "  def inicializarContadores(self,temp):\n",
        "    self.aceptados = 0\n",
        "    self.Total = 0\n",
        "    self.acc_prob_a = 0.\n",
        "    self.acc_prob_ad = 0.\n",
        "    self.SubTotal = 0.\n",
        "    self.an_step = 0\n",
        "    self.To = temp\n",
        "    self.Temp = temp\n",
        "\n",
        "  def pasoAnnealing(self):\n",
        "    \n",
        "    # Extraemos momentos del baño termico\n",
        "    self.ObjetoHMC.Po = self.Temp*np.random.randn(len(self.ObjetoHMC.Xo)) # Siempre muestreamos la distribucion de momentos antes de cada trayectoria acorde a la temperatura del sistema\n",
        "    # Valor del hamiltoniano inicial\n",
        "    self.Ho = self.GP.log_prob_verosimilitud_datos(*self.ObjetoHMC.Xo) + 0.5*np.sum(np.power(self.ObjetoHMC.Po,2),axis=0)\n",
        "    # Se itera la trayectoria\n",
        "    self.ObjetoHMC.ejecutarTrayectoria(self.Dt)\n",
        "    # Valor del hamiltoniano posterior\n",
        "    self.H = self.GP.log_prob_verosimilitud_datos(*self.ObjetoHMC.Xo) + 0.5*np.sum(np.power(self.ObjetoHMC.Po,2),axis=0)\n",
        "    # Diferencia entre hamiltonianos\n",
        "    self.Dif_H = self.H-self.Ho\n",
        "    # Obtenemos probabilida de aceptacion\n",
        "    self.acc_prob = np.minimum(1.,np.exp(-(1./self.Temp)*self.Dif_H))\n",
        "\n",
        "  def aceptacion(self):\n",
        "    self.Total = self.Total + 1\n",
        "    self.acc_prob_a = self.acc_prob_a*((self.Total-1)/self.Total) + (self.acc_prob/self.Total)\n",
        "    unif = np.random.uniform()\n",
        "    if unif > self.acc_prob:\n",
        "      # No se acepta la nueva configuracon\n",
        "      return 0\n",
        "    else:\n",
        "      # Se acepta\n",
        "      self.prev_Xo = self.ObjetoHMC.X\n",
        "      return 1\n",
        "\n",
        "    #print(unif,self.acc_prob,self.aceptados)\n",
        "\n",
        "  def forzarAceptacion(self):\n",
        "    '''\n",
        "    Si variamos dt es un metodo de ajustar la probabilidad de aceptacion dinámicamente. Lo hacemos sondeando el promedio de la \n",
        "    probabilidad de aceptacion dinamicamente\n",
        "    '''\n",
        "    self.SubTotal = self.SubTotal + 1\n",
        "    if (self.SubTotal > 10):\n",
        "      if (self.acc_prob_a < 0.45):\n",
        "        # Debemos intentar mejorar la aceptacion\n",
        "        self.Dt = self.Dt - self.Dt*(0.03)\n",
        "      elif (self.acc_prob_a > 0.55):\n",
        "        # Debemos intentar reducir la aceptacióón\n",
        "        self.Dt = self.Dt + self.Dt*(0.03)\n",
        "      self.SubTotal = 0\n",
        "\n",
        "  def reducirT(self,To,astep):\n",
        "    self.Temp = To*np.exp(-0.3*float(astep))\n",
        "\n",
        "  def annealing(self):\n",
        "    self.inicializarContadores(self.Temp)\n",
        "    while self.an_step < 50:\n",
        "      self.prev_Xo = self.ObjetoHMC.Xo \n",
        "      while self.aceptados < 100:\n",
        "        self.pasoAnnealing()\n",
        "        self.aceptados = self.aceptados + self.aceptacion()\n",
        "        self.forzarAceptacion()\n",
        "      self.an_step = self.an_step + 1\n",
        "      print(\"Paso de enfriamiento dado, temp actual :\",self.Temp, \" aceptado promedio :\", self.acc_prob_a,\" dt :\", self.Dt, \" n :\",self.N, \" total pasos probados :\", self.Total)\n",
        "      self.reducirT(self.To,self.an_step)\n",
        "    print(\"Resultado final:\",self.ObjetoHMC.Xo)\n",
        "\n",
        "\n",
        "  def diag_suma(self,k):\n",
        "    '''\n",
        "    Suma terminos de la diagonal k de la  matriz normalizando por el numero de elementos que contenga\n",
        "    '''\n",
        "    traza_k = np.trace(self.cross_element_matrix,offset=k)\n",
        "    return traza_k/float(len(self.cross_element_matrix)-k)\n",
        "\n",
        "\n",
        "  def aceptacionFrenteTemperatura(self,temperaturas, al):\n",
        "    '''\n",
        "    Devuelve array de aceptacion promedio frente temperaturas como input y el numero de iteraciones para calcular promedio\n",
        "    Implicito esta el potencial a minimizar, el paso temporal y el numero de iteraciones de monte - carlo hibridas\n",
        "    '''\n",
        "\n",
        "    e_partida = self.ObjetoHMC.Xo\n",
        "    acc_aver = np.zeros(len(temperaturas))\n",
        "\n",
        "    for id_temp in range(len(temperaturas)):    \n",
        "      self.inicializarContadores(temperaturas[id_temp])\n",
        "      self.prev_Xo = e_partida\n",
        "      for iteraciones in range(al): # Representa indices que van de 0 hasta longitud - 1\n",
        "        self.ObjetoHMC.Xo = self.prev_Xo\n",
        "        self.pasoAnnealing()\n",
        "        self.aceptados = self.aceptados + self.aceptacion()\n",
        "        if (self.aceptacion() == 1):\n",
        "          self.aceptados = self.aceptados + 1\n",
        "          self.acc_prob_ad = self.acc_prob_ad*((self.aceptados-1)/self.aceptados) + (self.acc_prob/self.aceptados)\n",
        "      print(\"tempratura :\",id_temp,\" prob media :\",self.acc_prob_a)\n",
        "      acc_aver[id_temp] = self.acc_prob_a\n",
        "    \n",
        "    return acc_aver\n",
        "    \n",
        "\n",
        "\n",
        "  def correlacionExploracion(self,sl):\n",
        "    '''\n",
        "    Dada una temperatura se analiza la correlacion unitaria entre entre el valor de la energia muestreada en función de cuantas transiciones sobre el espacio de fase son aceptadas\n",
        "\n",
        "    La correlacion unitaria es el siguiente calculo, C(a,s) = <(Ea - <E>)*(Ea+s-<E>)> / (<(Ea - <E>)*(Ea-<E>)> )\n",
        "\n",
        "    Notar que en esencia es suponer una correlacion estacionaria y normalizar al valor del primre elemento en la sucesion de terminos\n",
        "\n",
        "    sl es la longitud en cantidad de medidas a realizar, el alcance del indice que representa el tiempo\n",
        "    al es la cantidad de trayectorias a realizar, con lo que calculamos promedios\n",
        "    '''\n",
        "\n",
        "\n",
        "    self.inicializarContadores(self.Temp)\n",
        "    arrayEnergias = np.zeros(sl) \n",
        "    e_partida = self.ObjetoHMC.Xo\n",
        "    self.ObjetoHMC.Xo = e_partida #  + 1.1*np.random.randn(len(self.ObjetoHMC.Xo))\n",
        "    arrayEnergias[self.aceptados] = self.GP.log_prob_verosimilitud_datos(*self.ObjetoHMC.Xo)\n",
        "    while self.aceptados < sl-1: # Representa indices que van de 0 hasta longitud - 1\n",
        "      self.prev_Xo = self.ObjetoHMC.Xo\n",
        "      self.pasoAnnealing()\n",
        "      if self.aceptacion() == 1:\n",
        "        print(\"aceptacion promedio :\",self.acc_prob_a, \"aceptado n: \",self.aceptados)\n",
        "        #print(\"intento y si acepto\")\n",
        "        self.aceptados += 1\n",
        "        arrayEnergias[self.aceptados] = self.GP.log_prob_verosimilitud_datos(*self.ObjetoHMC.Xo)\n",
        "      #else:\n",
        "        #print(\"intento pero no acepto\")\n",
        "    \n",
        "    aver = np.sum(arrayEnergias)*(1./float(sl))\n",
        "    #print(\"Energias :\",arrayEnergias)\n",
        "    #print(\"aver :\",aver)\n",
        "\n",
        "\n",
        "    br_aE = arrayEnergias - aver # Como son arrays de numpy esta operacion amplia la dimension del promedio a todos los elementos de las energias\n",
        "\n",
        "    # \n",
        "    self.sq_sigma_aver = np.sum(np.power(br_aE,2))*(1./float(sl))\n",
        "    #print(\"sigma cuadrado :\",self.sq_sigma_aver)\n",
        "\n",
        "    # Matriz de correlación\n",
        "    br_aE = np.reshape(br_aE,(len(br_aE),1))\n",
        "    self.cross_element_matrix= np.matmul(br_aE,br_aE.T)\n",
        "\n",
        "    self.vdiag_suma = np.vectorize(self.diag_suma)\n",
        "    self.Corr = self.vdiag_suma(np.arange(sl))/self.sq_sigma_aver\n",
        "\n",
        "  def correlacionExploracion_1(self,al,sl):\n",
        "    '''\n",
        "    Dada una temperatura se analiza la correlacion unitaria entre entre el valor de la energia muestreada en función de cuantas transiciones sobre el espacio de fase son aceptadas\n",
        "\n",
        "    La correlacion unitaria es el siguiente calculo, C(a,s) = <(Ea - <E>)*(Ea+s-<E>)> / (<(Ea - <E>)*(Ea-<E>)> )\n",
        "\n",
        "    Notar que en esencia es suponer una correlacion estacionaria y normalizar al valor del primre elemento en la sucesion de terminos\n",
        "\n",
        "    sl es la longitud en cantidad de medidas a realizar, el alcance del indice que representa el tiempo\n",
        "    al es la cantidad de trayectorias a realizar, con lo que calculamos promedios\n",
        "    '''\n",
        "\n",
        "    arrayEnergias = np.zeros((al,sl)) \n",
        "    e_partida = self.ObjetoHMC.Xo\n",
        "    for i in range(al):\n",
        "      self.ObjetoHMC.Xo = e_partida #  + 1.1*np.random.randn(len(self.ObjetoHMC.Xo))\n",
        "      self.aceptados = 0\n",
        "      print(i,self.ObjetoHMC.Xo)\n",
        "      arrayEnergias[i,self.aceptados] = self.GP.log_prob_verosimilitud_datos(*self.ObjetoHMC.Xo)\n",
        "      self.Total = 0\n",
        "      self.acc_prob_a = 0.\n",
        "      self.SubTotal = 0.\n",
        "      while self.aceptados < sl-1: # Representa indices que van de 0 hasta longitud - 1\n",
        "        self.prev_Xo = self.ObjetoHMC.Xo\n",
        "        self.pasoAnnealing()\n",
        "        if self.aceptacion() == 1:\n",
        "          #print(\"intento y si acepto\")\n",
        "          self.aceptados += 1\n",
        "          arrayEnergias[i,self.aceptados] = self.GP.log_prob_verosimilitud_datos(*self.ObjetoHMC.Xo)\n",
        "        #else:\n",
        "          #print(\"intento pero no acepto\")\n",
        "    \n",
        "    \n",
        "    aver = np.sum(np.sum(arrayEnergias,axis=0))*(1./float(al))\n",
        "\n",
        "\n",
        "    br_aE = (arrayEnergias - aver)*np.sqrt(1./float(al)) # Como son arrays de numpy esta operacion amplia la dimension del promedio a todos los elementos de las energias\n",
        "\n",
        "    print(aver)\n",
        "    print(arrayEnergias)\n",
        "    print(br_aE)\n",
        "\n",
        "    # Matriz de correlación\n",
        "    cross_element_matrix = np.matmul(br_aE.T,br_aE)\n",
        "    print(cross_element_matrix)\n",
        "\n",
        "    # Asumiendo que las correlaciones son estacionarias, esto es que dependen de la distancia temporal que separan las medidas, extraemos información adicional de la anterior matriz\n",
        "    # Primero Consideramos la matriz formada por las correlaciones punto a punto por encima (U) y por debajo (D) de la diagonal y \n",
        "    # Vamos promediando donde haya puntos disponibles y en caso contrario añadimos ceros. La idea es con la información que tenemos \n",
        "    # promediar para obtener C(x,x') - C(|x-x'|).         \n",
        "    corr_U = np.asarray([np.concatenate((cross_element_matrix[i,i:sl]/cross_element_matrix[i,i],np.zeros(i)) ) for i in range(sl)])\n",
        "    corr_D = np.asarray([np.flip(np.concatenate((np.zeros(sl-i-1),cross_element_matrix[i,0:i+1]/cross_element_matrix[i,i]))) for i in range(sl)])\n",
        "\n",
        "    # Seguidamente, estas dos matrices son equivalentes en la aproximacion y se suman para obtener el promedio con la cantidad de puntos\n",
        "    # que se han sumado. Estos puntos para promediar van desde 2*self.P a 2, porque es un promediado sobre dimensiones de la matriz de correlacion\n",
        "    corrEst = np.sum(corr_U + corr_D,axis=0)\n",
        "    promediadoMatriz = 2*(sl*np.ones(sl)-np.arange(sl)) # Este array contiene el numero de trayectorias usadas por cada elemento del promediado final extraida de la matriz de correlacion\n",
        "\n",
        "    self.Corr =  corrEst/promediadoMatriz \n",
        "    self.Corr = cross_element_matrix[0,:]\n",
        "    \n",
        "      \n",
        "\n",
        "\n",
        "  class hybridMontecarlo():\n",
        "\n",
        "    def __init__(self,x,temp,dt,n,gp):\n",
        "      self.Xo = np.asarray(x) # En este formalismo de procesos gausianos son una lista de hiperparámetros\n",
        "      self.Po = None\n",
        "      self.Temp = temp\n",
        "      self.Dt = dt\n",
        "      self.t = 0. # Inicializacion del tiempo\n",
        "      self.N = n\n",
        "      self.Nd = len(self.Xo)\n",
        "      self.GP = gp \n",
        "      #self.trayectoria, self.ax_tray = plt.subplots(1,1)\n",
        "    def updateStepIter(self,):\n",
        "      '''\n",
        "      Ejecuta avance en el integrador simpléctico y actualiza las fuerzas calculadas\n",
        "      '''\n",
        "      self.Fo = self.GP.der_log_prob_ver_hiper(*self.Xo)\n",
        "      self.update_x_verlet()\n",
        "      self.F = self.GP.der_log_prob_ver_hiper(*self.X)\n",
        "      self.update_p_verlet()\n",
        "      self.Fo = self.F\n",
        "      self.t += self.Dt\n",
        "\n",
        "    def update_x_verlet(self):\n",
        "      '''\n",
        "      La operacion se realiza sobre ndarray\n",
        "      '''\n",
        "      self.X = self.Xo + self.Dt*(self.Po + (0.5*self.Dt*self.Fo))\n",
        "\n",
        "    def update_p_verlet(self):\n",
        "      '''\n",
        "      La operacion se realiza sobre ndarray\n",
        "      '''\n",
        "      self.P = self.Po + 0.5*self.Dt*(self.Fo + self.F)\n",
        "\n",
        "    #@numba.njit\n",
        "    def ejecutarTrayectoria(self,tray_dt):\n",
        "      '''\n",
        "      Desarrolla una trayectoria en el integrador simplectico de self.N iteraciones\n",
        "      '''\n",
        "      self.Dt = tray_dt\n",
        "      for index_t in range(self.N):\n",
        "        self.updateStepIter()\n",
        "        self.Xo = self.X\n",
        "        self.Po = self.P\n",
        "        #self.ploteado(False)\n",
        "      #self.ploteado(True)\n",
        "\n",
        "\n",
        "    def ploteado(self,mostrar):\n",
        "      '''\n",
        "      Muestra punto x integrado hasta ahora frente al indice del tiempo\n",
        "      '''\n",
        "      for i in range(self.Nd):\n",
        "        self.ax_tray.plot(self.t,self.X[i],'ob')\n",
        "      if mostrar == True:\n",
        "        print(\"se ha mostrado\")\n",
        "        self.trayectoria.show()"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VpUiW0BdOrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class pruebaHMC():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def log_prob_verosimilitud_datos(self,*hiper):\n",
        "    arrayEntrada = np.asarray(hiper)\n",
        "    return (1./10.)*np.sum(np.sin(8*np.pi*arrayEntrada)/np.sin(2*np.pi*arrayEntrada))\n",
        "\n",
        "  def der_log_prob_ver_hiper(self,*hiper):\n",
        "    return np.asarray([-(np.pi/5.)*(   (4*np.cos(8*np.pi*i)*np.sin(2*np.pi*i)-np.sin(8*np.pi*i)*np.cos(2*np.pi*i)     ) /  np.power(np.sin(2*np.pi*i),2)   ) for i in hiper])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7Ogka96GyNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class datosVisualizacion():\n",
        "  '''\n",
        "  Esta clase contiene los datos de entrenamiento y realizaciones de los procesos gaussianos para la visualización de los mismos\n",
        "  '''\n",
        "  def __init__(self,Titulo):\n",
        "    self.x = []\n",
        "    self.y = []\n",
        "    self.sigma = []\n",
        "    self.realizacion_dict = {}\n",
        "    self.titulo = Titulo\n",
        "    self.inicializacionPlot()\n",
        "\n",
        "  def inicializacionPlot(self):\n",
        "    '''\n",
        "    Inicializa el objeto matplotlib\n",
        "    '''\n",
        "    self.fig,self.ax = plt.subplots(nrows=1,ncols=1,figsize=(10,10))\n",
        "    self.ax.set_title(self.titulo)\n",
        "    self.fig_hm, self.ax_hm = plt.subplots(nrows=1,ncols=1,figsize=(10,10))\n",
        "\n",
        "  def add_covariance(self, cov):\n",
        "    '''\n",
        "    Añada matriz de covarianza y alternativamente calcula la covarianza del proceso gaussiano sobre el dominio\n",
        "    '''\n",
        "\n",
        "    self.cov_GP = cov\n",
        "\n",
        "  def add_mean(self,X,Mean):\n",
        "    '''\n",
        "    Almacena la desviación estándar de un proceso gausiano dado\n",
        "    '''\n",
        "    self.x_mean = X\n",
        "    self.mean = Mean\n",
        "\n",
        "\n",
        "  def add_sigma(self,X,Sigma):\n",
        "    '''\n",
        "    Almacena la desviación estándar de un proceso gausiano dado\n",
        "    '''\n",
        "    self.x_sigma = X\n",
        "    self.sigma = Sigma\n",
        "    self.meanMarker = 'r-'\n",
        "\n",
        "  def add_train_data(self,X,Y):\n",
        "    self.xtrain = X\n",
        "    self.ytrain = Y\n",
        "    self.marker = 'b*'\n",
        "\n",
        "  def add_data(self,X,Y,label):\n",
        "    self.x.append(X)\n",
        "    self.y.append(Y)\n",
        "    self.realizacion_dict[label] = len(self.x)-1\n",
        "\n",
        "  def add_corrPuntoPunto(self,corrPP, corrInputs):\n",
        "    '''\n",
        "    Añade correlaciones punto a punto sobre un dominio dado por los valores corrInputs\n",
        "    '''\n",
        "    self.corrPP = corrPP\n",
        "    self.corr_in = corrInputs\n",
        "\n",
        "  def add_data_plot(self,label):\n",
        "    try:\n",
        "      self.ax.plot(self.x[self.realizacion_dict[label]],self.y[self.realizacion_dict[label]],'g--')\n",
        "    except:\n",
        "      print('No existe datos referentes a etiqueta :',label)\n",
        "\n",
        "  def add_train_data_plot(self):\n",
        "    try:\n",
        "      self.ax.plot(self.xtrain,self.ytrain,self.marker)\n",
        "    except:\n",
        "      print('No existen datos de entrenamiento')\n",
        "\n",
        "  def add_mean_plot(self):\n",
        "    try:\n",
        "      self.ax.plot(self.x_mean,self.mean,self.meanMarker)\n",
        "    except:\n",
        "      print('No existen datos de entrenamiento')\n",
        "\n",
        "\n",
        "\n",
        "  def contorno_sigma(self):\n",
        "    '''\n",
        "    Muestra en pantalla contorno de 1 y 2 veces los valores de sigma del proceso gausiano\n",
        "    '''\n",
        "    self.ax.fill(np.concatenate((self.x_sigma,self.x_sigma[::-1])),\n",
        "             np.concatenate((self.mean - 1.9600 * self.sigma,\n",
        "                             (self.mean + 1.9600 * self.sigma)[::-1])),\n",
        "             alpha=.45, fc='y', ec='None', label='95% confidence interval')\n",
        "    self.ax.fill(np.concatenate((self.x_sigma,self.x_sigma[::-1])),\n",
        "             np.concatenate((self.mean - 1.000 * self.sigma,\n",
        "                             (self.mean + 1.000 * self.sigma)[::-1])),\n",
        "             alpha=.35, fc='b', ec='None', label='68% confidence interval')\n",
        "    \n",
        "  def plotCorrPuntoPunto(self,indices):\n",
        "    '''\n",
        "    Visualiza correlaciones punto a punto para los inputs dados por sus indices en la lista indices como argumento del metodo\n",
        "    '''\n",
        "\n",
        "    ' Generamos y visualizamos las imagen directamente en este metodo'\n",
        "    self.fig_cpp, self.ax_cpp = plt.subplots(nrows=1,ncols=1,figsize=(10,10))\n",
        "    try:\n",
        "      [self.ax_cpp.plot(self.corr_in,self.corrPP[indice],'-') for indice in indices] \n",
        "    except:\n",
        "      print('No existe datos referentes referentes a correlaciones punto a punto')\n",
        "    self.ax_cpp.grid(True)\n",
        "    self.fig_cpp.show()\n",
        "\n",
        "\n",
        "\n",
        "  def mostrarPlot(self):\n",
        "    '''\n",
        "    Muestra plot\n",
        "    '''\n",
        "    self.add_mean_plot()\n",
        "    self.add_train_data_plot()\n",
        "    self.contorno_sigma()\n",
        "    self.ax.grid(True)\n",
        "    self.fig.show()\n",
        "\n",
        "  def hmapCov(self):\n",
        "    '''\n",
        "    Visualiza covarianza como campo bidimensional\n",
        "    '''\n",
        "    plotRange = np.arange(len(self.cov_GP))\n",
        "    heatmap = self.ax_hm.pcolormesh(self.cov_GP,cmap='RdBu_r')\n",
        "    self.ax_hm.axis([plotRange.min(), plotRange.max(), plotRange.max(), plotRange.min()])\n",
        "    self.fig_hm.colorbar(heatmap, ax=self.ax_hm)\n",
        "    self.fig_hm.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKwMJ0tWfspi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}